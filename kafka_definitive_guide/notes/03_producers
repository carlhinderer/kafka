----------------------------------------------------------------------------
|  CHAPTER 3 - KAFKA PRODUCERS                                             |
----------------------------------------------------------------------------

- Kafka Producers

    - In this chapter, we'll look at Kafka's built-in 'KafkaProducer' and 'ProducerRecord' objects.
        In addition to these built-in clients, Kafka has a binary wire protocol, so many third party
        clients have been created as well.


    - Common Use Cases for Producers

        - Recording user activities for auditing or analysis
        - Recording metrics
        - Storing log messages
        - Recording information from smart appliances
        - Communicating asynchronously with other applications
        - Buffering information before writing to an application


    - For every use case we should ask ourselves:

        1. Is every message critical, or can we tolerate loss of messages?
        2. Are we OK with duplicated messages?
        3. Are there strict latency or throughput requirements?


    - For instance, we are sending credit card processing messages.  We cannot lose messages or tolerate
        duplicated messages.  Throughput will be high (1 million messages per s) and latency should be
        under 500 ms.


    - Another use case is storing click events from a website.  In this case, some message loss or
        duplication is tolerable.  Latency can be high as long as it doesn't affect the user experience.



- High-Level Producer Flow

    1. We start producing messages by creating a 'ProducerRecord', which must have a topic and value.
         Optionally, we can also specify a key, a partition, a timestamp, and/or a collection of 
         headers.

       Once we send the ProducerRecord, the producer will serialize the key and value objects to byte
         arrays so they can be sent over the network.


    2. Next, if we didn't explicitly specify a partition, the data is sent to a partitioner.  The
         partitioner will choose a partition for us, usually based on the 'ProducerRecord' key.

       Once a partition is selected, the producer knows which topic and partition the record will go
         to.  It adds the message to a batch that will go to the same topic and partition.  A separate
         thread is responsible for sending those batches to the appropriate Kafka brokers.


    3. When the broker retrieves the messages, it sends back a response.  If the messages were written
         successfully, it will return a 'RecordMetadata' object with the topic, partition, and
         offset of the record within the partition.

       If the broker failed to write the messages, it will return an error.  When the producer receives
         an error, it may retry sending the message a few more times before giving up.



                                ProducerRecord[Topic, Value, (Partition), (Key)]
                                                      |
                                                    Send()
                                                      |
                                                      V
                                                  Serializer
                                                      |
                                                      V
                             ^                   Partitioner
                             |                        |
                           Exception       -------------------------
                             |             |                       |
                            No             V                       V
                             |         Topic A                  TopicB
                     ^       |  Yes--->Partition 0              Partition 1
                     |       |   |     ------------             ------------
                  Return     Retry?    Batch 0                  Batch 0
                Metadata       |       Batch 1                  Batch 1
                     |        Yes      Batch 2                  Batch 2
                     |         |          |                       |
                     No------Fail?        -------------------------
                               |                      |
                               |                      V
                               |-----------------Kafka Broker




- Constructing a Kafka Producer

    - First, we need to create a producer object with the properties we want to pass to the producer.
        There are 3 mandatory properties:

        bootstrap.servers                  # List of host:port pairs of brokers the producer will use
                                           #   to establish initial connection to the cluster
                                           #   (Does not need to include all brokers, but should include 2)

        key.serializer                     # Name of class used to serialize keys

        value.serializer                   # Name of class used to serialize values


    - The standard Kafka serializers are:

        ByteArraySerializer                # Doesn't do much
        StringSerializer
        IntegerSerializer



    - Note that you still have to set the 'KeySerializer' even if you only intend to send values.  In
        that case, you can use the 'VoidSerializer'.


    - Here is an example of the most basic configuration:

       Properties kafkaProps = new Properties();

       kafkaProps.put("bootstrap.servers", "broker1:9092,broker2:9092");
       kafkaProps.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
       kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

       producer = new KafkaProducer<String, String>(kafkaProps);



- Sending a Message to Kafka

    - Now that we have instantiated a producer, we can start sending messages.  There are 3 primary 
        methods of sending messages:

        1. Fire-and-forget = We send a message, and don't really care whether it arrives successfully
                               or not.

        2. Synchronous send = Technically, a Kafka producer is always asynchronous - we send a message,
                                and the 'send()' method returns a 'Future' object.  However, we use
                                'get()' to wait on the 'Future' before sending the next record.

        3. Asynchronous send = We call the 'send()' method with a callback function, which gets
                                 triggered when it receives a response from the Kafka broker.


    - Here is the simplest way to send a message:

        ProducerRecord<String, String> record =
            new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

        try {
            producer.send(record);
        } catch (Exception e) {
            e.printStackTrace();
        }

      We are using fire-and-forget here, and we're ignoring any errors we receive back from Kafka.
        The exceptions we are catching are thrown before sending the message to Kafka.



- Sending a Message Synchronously

    - Sending a message synchronously is simple, and allows the producer to catch exceptions when
        Kafka returns an error or send retries are exhausted.  The tradeoff is a performance hit from
        blocking.


    - To send a message synchronously:

        ProducerRecord<String, String> record =
            new ProducerRecord<>("CustomerCountry", "Precision Products", "France");

        try {
            producer.send(record).get();
        } catch (Exception e) {
            e.printStackTrace();
        }


    - 'KafkaProducer' has 2 types of errors:

        1. 'Retriable' errors that can be resolved by sending the message again
        2. Errors that cannot be resolved by retry like the message being too big

      The KafkaProducer can be configured to retry automatically if a retriable error is received.



- Sending a Message Asynchronously

    - Blocking synchronously on every message sent will cause a drastic performance penalty.  On the
        other hand, if we just send all our messages without waiting for replies, it will be much
        faster.

      In most cases, we don't actually need a reply.  Kafka sends back the topic, partition, and offset
        of the record that was written.  Most applications don't need this information.


    - On the other hand, we do need to know when we failed to send a message completely, so we can throw
        an exception, log an error, or write to an 'errors' file for later analysis.


    - To send messages asynchronously and still handle error scenarios, we can use callbacks.

        private class DemoProducerCallback implements Callback {
            @Override
            public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                if (e != null) {
                    e.printStackTrace();
                }
            }
        }

        ProducerRecord<String, String> record =
            new ProducerRecord<>("CustomerCountry", "Biomedical Materials", "USA");

        producer.send(record, new DemoProducerCallback());



- Configuring Producers

    - Configuration parameters for producers:

        client.id              # Logical id for client, makes log tracing much easier, can be any string

        acks                   # Number of replicas that must receive a record before write is
                               #   considered successful
                               #
                               #   acks=0             # Fire and forget
                               #   acks=1             # Leader receives message (default)
                               #   acks=all           # All in sync replicas receive the message


    - Note that the 'acks' is a tradeoff for Producer latency, not end-to-end latency.  In order to
        maintain consistency, Kafka will not allow consumers to read records until all in-sync
        replicas.  So the end-to-end latency is the same whether 'acks' is 0, 1, or 'all'.



- Message Delivery Configuration

    - The Producer has multiple configuration parameters that control how much time to wait until
        we give up on a 'send()' call.

      
    - Since Kafka 2.1, we divide the time spent sending a ProducerRecord into 2 time intervals that
        are handled separately:

        1. Time until an async call to 'send()' returns.  During this interval, the thread that called
             'send()' will be blocked.

        2. From the time an async call to 'send()' returned successfully until the callback is triggered
             (success or failure).


          max.block.ms
        |----------------|  linger.ms
                         |-------------|
                                       |---------|  retry.backoff.ms
                                                 |--------------------|  request.timeout.ms
                                                                      |-----------------------|

                                                delivery.timeout.ms 
                         |--------------------------------------------------------------------|


        |     send()     |  Batching   | Await   |   Retries          |  Inflight             |
                                         send



    - Note that: delivery.timeout.ms >= (linger.ms + retry.backoff.ms + request.timeout.ms)


    - Here is a description of the delivery config parameters:

        max.block.ms           # Max amount of time to block on send(), exception is thrown when reached

        delivery.timeout.ms    # Max amount of time to spend sending and retrying

        request.timeout.ms     # Max amount of time to wait on reponse from server on a single try

        retries                # Number of retries

        retry.backoff.ms       # Time to wait between retries (100 ms by default)


    - In general, there is no point in handling retries in application logic, since the Producer does
        it for you.  Focus your efforts on handling nonretriable errors or cases where retry attempts
        were exhausted.


    - Some cases are extremely sensitive to ordering guarantees.  For instance, you want a message
        depositing $100 to arrive before a message withdrawing $100.

      Kafka guarantees ordering in a partition, but retries could cause events to arrive out of order.
        If you need to guarantee order, the best way is to send 'enable_idempotence=true'.  This
        guarantees order for up to 5 in-flight requests, and also guarantees retries will not
        introduce duplicates.



- Other important configuration parameters:

        linger.ms              # Amount of time to wait for additional messages before sending batch

        buffer.memory          # Amount of memory to use buffering messages before sending

        compression.type       # Can use snappy, gzip, lz4, or zstd (none by default)

        batch.size             # Amount of memory (in bytes) used for each batch before sending

        max.in.flight.requests.per.connection   # Number of messages producer will send to server 
                                                #   without receiving responses

        max.request.size       # Maximum size of entire batch of messages

        receive.buffer.bytes   # Sizes of TCP send and receive buffers used by sockets when sending
        send.buffer.bytes      #   and receiving data

        enable.idempotence     # Used to support exactly-once semantics, producer will attach 
                               #   sequence number that Kafka will use to reject duplicates
                               #
                               # Note that enabling this also requires:
                               #   max.in.flight.requests.per.connection = 5 or less
                               #   retries = 1 or greater
                               #   acks = all



- Serializers


- Partitions


- Headers


- Interceptors


- Quotas and Throttling